Security

Darknet diaries

Operation        | from MARFOR CYBER about attacking ISIS media
Glowing Symphony |

GALE-507-M 

iv4CRgEPySw8bJM 

10.50.44.245

10.50.20.250:8000/

Jo 10.50.47.112
Wat 10.50.37.149


Penetration Testing
_______________________________________________________________________________________________________________________

We will always make a tunnel to our jump box first. It is in the grey space. The username and password is student and password is (bad)password. 

Penetration testing is ethical hacking in order to find weaknesses in security.
The rationale promotes critical thinking, so when you are attacking a network you have to think outside of the box in order to get in.

Phase 1
Mission definition is when they set boundaries and rules

Phase 2
Recon, doing either passive or active recon. Using tools like nmap (more active so not necessarily), google dorking, nslookup, social media, etc.

Phase 3
Footprinting, more in depth recon using nmap and nmap script, the more active side, 

Phase 4
Exploitation and Initial Access, gain an initial foothold on network

Phase 5
Post-Exploitation, establish persistence, escalate privileges, cover your tracks, exfilltrate target data

Phase 6
Document Mission, documentation for different audiences

Penetration Test Reporting, an executive summary (breaks down everything as quickly as possible) and technical summary (has a lot more jargon)
When reporting have reasons to report, what to report, screen captures. 

Darknet diaries


Recon
_______________________________________________________________________________________________________________________

nmap scan scripts
OSINT, using google, google dorking, social media, linkden, alternate ports, versions of services running, OS.
DOD states "produced from publicly available information that is collected, exploited, and disseminated in a timely manner to an appropriate audience for addressing a specific intelligence requirement."

Limitations on Collection
Data to Collect, Web Data, Sensitive Data, Publicly Accessible, Social Media, Domain and IP Data

Scraping Data
quotes.toscrape.com
pip install lxml requests
Look at the script on the slides for the scraping data
You will change page and authors that's about it

#!/usr/bin/python
import lxml.html
import requests

page = requests.get('http://quotes.toscrape.com')
tree = lxml.html.fromstring(page.content)

authors = tree.xpath('//small[@class="author"]/text()')

print ('Authors: ',authors)






















